---
title: "Movie Recommender - HarvardX Capstone"
author: "David Edelman"
date: "4/22/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r data prep, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))
movielens <- left_join(ratings, movies, by = "movieId")

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

# Learners will develop their algorithms on the edx set
# For grading, learners will run algorithm on validation set to generate ratings
rm(dl, ratings, movies, test_index, temp, movielens, removed)

```

## Executive Summary
People are always wanting to know if they should see a certain movie, whether it is new in the theaters, or an older movie available on other media. However, individual tastes widely vary when it comes to enjoyment of movies. Movie reviews and ratings often inform this decision, so by using a vast accumulation of movie reviews from individuals, we can create a algorithm to predict how a certain individual would rate the movie, and hence their level of enjoyment.

We will take almost 10 million movie reviews from individuals that logged movie review on the site MovieLens (<http://movielens.org>), explore the data to see what insights we can glean from it, and using those insights construct a prediction algorithm. We will test the predictive power against a validation set of 1 million records by using the Root Mean Square Error (RMSE) metric.

## Data Exploration and Wrangling
The data set we are using is relatively simple. There are 5 predictors along with the "rating" dependant variable:

* userId - an integer identifier for each unique user; the value has no inherent meaning
* movieId - an integer identifier for each unique movie; the value has no inherent meaning
* timestamp - represents the date and time of the rating by storing the number of seconds since 1 January 1970
* title - the title of the movie, including the year of release
* genre - a list of all of the genres that MovieLens.org ascribed to the individual movie, listed alphabetically, concatenated by the pipe character (|)
* rating - the dependent variable; a set of numbers from 0.5 to 5, incrementing by 0.5

### Ratings
```{r, echo=FALSE, warning=FALSE}
edx %>% ggplot(aes(x=rating))+geom_histogram(stat="count")
```

A distribution of the number of reviews per rating shows that most ratings are 4 stars, followed by 3 stars. The "1/2 star" ratings are uncommon, so for the purposes of looking at a distribution, we will round the 1/2 stars ratings down.

```{r, echo=FALSE, warning=FALSE}
edx %>% mutate(gp_rating = floor(rating)) %>%
  ggplot(aes(x=gp_rating))+geom_histogram(stat="count")+
  xlab("rating")

```

The distribution appears approximately normal with a negative skew. The mean rating *mu* is 3.51. Since the distribution is not continuous, median and standard deviation are not very meaningful.

### Genres

There are 797 unique combinations of genres in the dataset:

```{r}
dim(table(edx$genres))
```

We will split the pipe-concatenated genres into individual genres, but to do this we need to know what the largest concatenated string is.

```{r}
#Find the longest genre entry
g <- names(table(edx$genres))
g[which.max(str_length(g))]
```

With a maximum of 8 genres concatenated together, we can now split the genre column into 8 separate columns, each with one genre ("NA" will be put in place for each missing column value). 

```{r}
#Since the longest has 8, we will split into 8 columns
#(NA will populate where there are not 8 genres)
genres <- c("genre1", "genre2", "genre3", 
            "genre4", "genre5", "genre6",
            "genre7", "genre8")

edx <- edx %>% separate(genres, into=genres, 
                        sep="[|]", fill="right", remove=FALSE, extra="merge")
```
```{r, echo=FALSE}
edx <- edx %>% mutate_at(genres, ~as.factor(.x))

#Get a single vector of all of the individual genre names
all_genres <- rbind(distinct(data.frame(genre = levels(edx$genre1))),
                    distinct(data.frame(genre = levels(edx$genre2))),
                    distinct(data.frame(genre = levels(edx$genre3))),
                    distinct(data.frame(genre = levels(edx$genre4))),
                    distinct(data.frame(genre = levels(edx$genre5))),
                    distinct(data.frame(genre = levels(edx$genre6))),
                    distinct(data.frame(genre = levels(edx$genre7))),
                    distinct(data.frame(genre = levels(edx$genre8))))

all_genres <- as.character(distinct(all_genres)$genre)

edx <- edx %>% mutate_at(genres, ~as.character(.x))
```

To get an idea of ratings distribution across the genres, we plot histograms for each genre, using the rating of the first genre alphabetically (genre1) as a suitable approximation for the mean across all movies containing that genre. (rounding the 1/2 star ratings down):

```{r, warning=FALSE}
edx %>% mutate(gp_rating = floor(rating)) %>%
  ggplot(aes(x=gp_rating))+geom_histogram(stat="count")+facet_wrap(~genre1, scales="free_y")
```

Just about all of the genres show a distribution heavily skewed towards the 3, 3.5, 4, and 4.5, so we may not see much benefit to this feature by itself in the prediction algorithm. However, there may be ways to use it in combination with other features.

### Dates
#### Year of Review/Rating

The year in which the user created the review may be of use for exploration and prediction. We can use the "timestamp" variable to extract a year. Since "timestamp" represents the number of seconds elapsed since 1 Jan 1970, we will convert to a date and extract the year.

```{r}
#Add review year
edx <- edx %>% 
  mutate(review_yr = year(as.Date(((edx$timestamp/60)/60)/24,
                                  origin="1970-1-1")))

table(edx$review_yr) %>% as.data.frame() %>% arrange(desc(Freq)) %>% grid.table()
```

As we see, all years have more than 100,000 ratings exccept for the first and last years of the range. Now lets look at the mean rating for each review year that is not 1995 or 2009. We plot as a line chart simply to make the trend more visible, and reverse the x-axis to show as the "age" of the review.

```{r}
edx %>% filter(review_yr != 1995 & review_yr != 2009) %>%
  group_by(review_yr) %>% summarize(mean_rt = mean(rating)) %>%
  ggplot(aes(x=review_yr, y=mean_rt))+geom_line()+scale_x_reverse()
```

As we see from the plot, the mean rating is between approximately 3.425 and 3.620. If there is a trend, it appears to be a slightly increasing mean as the ratings get older.

#### Date of Movie Release

As with the year of the rating, the year the movie was released may have some exploratory or predictive value. The "title" variable contains the year, so we will need to extract it. Fortunately, the year of release is at the end of the title, enclosed in parenthesis. This allows for an easy extraction, although a regular expression technique could also be used. The year value starts at the 5th string element from the end. We then have to strip off the close parenthesis before it can be converted to a number. Since we still have the title in the data set, we do not need the title with the year stripped off.

```{r}
edx <- edx %>% separate(title, into=c("ttl", "movie_yr"), sep= -5, 
                        remove=FALSE, fill="right", extra="merge")

edx <- edx %>% mutate(movie_yr = as.numeric(sub(")", "", edx$movie_yr)))
edx <- edx %>% select(-ttl)

range(edx$movie_yr)
```

We see that there are movies from as long ago as 1915, and as recent as 2008. Like the year of review, we will look at the mean rating per year of release, again with a "reversed" x-axis.

```{r, message=FALSE, warning=FALSE}
edx %>% 
  group_by(movie_yr) %>% summarize(mean_rt = mean(rating)) %>%
  ggplot(aes(x=movie_yr, y=mean_rt))+geom_line()+scale_x_reverse()+
  geom_smooth(linetype = 2, se=FALSE)
```

There appears to be a kind of trend where newer movies are rated lower and the mean rating increases until it peaks around 1950 then falls off again. But since the actual line looks more like a seismograph readout (high variability year to year), with the mean bouncing all over the place, calling the deviations "trends" may be over-simplifying things. 

#### "Nostalgia" Index
Finally, we calculate a "nostalgia index", defined as the time between release of the movie and the individual review. The thinking is that older movies, even ones within the range of the review years, may be rated differently than more recent movies.

```{r}
#Calculate years between movie release and review; negative numbers are assumed
#to be data errors and will be set to 0
edx <- edx %>% mutate(nostalgia_idx = ifelse(review_yr < movie_yr, 
                                             0,
                                             review_yr - movie_yr))

```

Like movie year and review year, we are interested in the mean rating for a film with a given "nostalgia index"

```{r}
edx %>% group_by(nostalgia_idx) %>% summarize(mean_rt = mean(rating)) %>% 
  ggplot(aes(x=nostalgia_idx, y=mean_rt))+geom_line()
```

The curve looks similar to the movie year, with less overall variation year to year. This may be a good candidate to represent the age of a movie in the prediction algorithm.

### User and Genre
We have split the single "genres" column into its constituent genres (genre1 thru genre8), and looked at a sample distribution, but we should explore further and look at the mean rating per genre, for every movie that is assigned to that genre. Because the genres are listed alphabetically, and not in some order indicating that a movie is more, for example, "Comedy" than it is "Horror", we need to comb through all of the movies and find which have been assigned to each genre. We previously stored the list of genres in all_genres:

```{r}
all_genres
```

We define a function to find the mean across the population that has each genre as one of its listed genres, then apply that function for each genre.

```{r}
find_genre_mean <- function(x) {
  tmp <- edx %>% mutate( gr = ifelse (genre1 == x | genre2 == x |
                             genre3 == x | genre4 == x |
                             genre5 == x | genre6 == x |
                             genre7 == x | genre8 == x, x, NA) )
  tmp %>% filter(! is.na(gr)) %>% group_by(gr) %>% summarize(mean_rt = mean(rating)) %>% .$mean_rt
}

gr <- sapply(all_genres, find_genre_mean)
grd <- data.frame(genre=names(gr), mean_rt = gr, stringsAsFactors = FALSE)
grd %>% arrange(genre) %>% grid.table(theme=ttheme_minimal(base_size = 8))
```

We have seen previously the distribution of ratings for the various genres (see **Genres** section, above), but we want to visualize the mean rating per genre for each user. We will first gather together the list of all users and all genres for which they have given ratings. Then we plot the mean rating for that user and genre, then overlay the overall population mean for the genre.

```{r}
gu <- rbind(edx %>% select(userId, genre1, rating) %>% mutate(genre = genre1) %>% select(-genre1),
            edx %>% filter(! is.na(genre2)) %>% 
              select(userId, genre2, rating) %>% mutate(genre = genre2) %>% select(-genre2),
            edx %>% filter(! is.na(genre3)) %>% 
              select(userId, genre3, rating) %>% mutate(genre = genre3) %>% select(-genre3),
            edx %>% filter(! is.na(genre4)) %>% 
              select(userId, genre4, rating) %>% mutate(genre = genre4) %>% select(-genre4),
            edx %>% filter(! is.na(genre5)) %>% 
              select(userId, genre5, rating) %>% mutate(genre = genre5) %>% select(-genre5),
            edx %>% filter(! is.na(genre6)) %>% 
              select(userId, genre6, rating) %>% mutate(genre = genre6) %>% select(-genre6),
            edx %>% filter(! is.na(genre7)) %>% 
              select(userId, genre7, rating) %>% mutate(genre = genre7) %>% select(-genre7),
            edx %>% filter(! is.na(genre8)) %>% 
              select(userId, genre8, rating) %>% mutate(genre = genre8) %>% select(-genre8)
)

gu <- gu %>% group_by(userId, genre) %>% summarize(mean_rt = mean(rating))
```


```{r, echo=FALSE}
###Do same data transformations to validation set
#Review Year
validation <- validation %>% 
  mutate(review_yr = year(as.Date(((validation$timestamp/60)/60)/24, origin="1970-1-1")))

#Movie Year
validation <- validation %>% separate(title, into=c("ttl", "movie_yr"), sep= -5, 
                        remove=FALSE, fill="right", extra="merge")

validation <- validation %>% 
  mutate(movie_yr = as.numeric(sub(")", "", validation$movie_yr))) %>% 
  select(-ttl)

#Nostalgia Index
validation <- validation %>% 
  mutate(nostalgia_idx = ifelse(review_yr < movie_yr, 0, review_yr - movie_yr))

#Genres
validation <- validation %>% separate(genres, into=genres, 
                        sep="[|]", fill="right", remove=FALSE, extra="merge")

```

## Modelling
We will do a relatively simple prediction algorithm based on the mean of the ratings in the training set, and determine the accuracy of the algorithm by using Root Mean Square Error (RMSE):

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^n \left( y_i-y \right) ^2}
$$

where ${y_i}$ is the predicted value and ${y}$ is the true value ("rating" in the validation set). For ease of use we define the population mean *mu* and a function for the RMSE

```{r}
mu <- mean(edx$rating)

RMSE <- function(x) {sqrt(mean((x - validation$rating)^2))}

RMSE(mu)
```
```{r, echo=FALSE}
results <- data.frame(model = "Population Mean", RMSE = RMSE(mu))
```

If we predicted each movie to simply have the same rating, that being the population mean rating, our RMSE would be 1.061. We will now look at "biases" or "effects" that can be applied to the population mean to bring the prediction closer to the actual rating and hence reduce the RMSE.

**NOTE**: When adding in "effects", we will confine the predicted rating to 0.0 thru 5.0, inclusively, since no rating outside of that range were available to the users.

### Movie effect
An individual movie may be more or less popular than average, so the prediction for that movie should be effected by the overall popularity (or lack thereof) of a given movie. To calculate this "movie effect", we find, for each movie (represented by *movieId*) the mean, over all reviews, of the difference between each rating and the population mean.

```{r}
#Find the mean effect per movie
movie <- edx %>% group_by(movieId) %>% summarize(bmov = mean(rating-mu))

#Predict by adding the movie effect to the population mean
pred <- validation %>% left_join(movie, by="movieId") %>%
  mutate(pred = ifelse(bmov+mu > 5, 5, bmov+mu)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Movie Effect", RMSE = RMSE(pred)))
```

We have reduced our RMSE considerably to 0.944.

### User effect
Like the movie effect, individual users may tend to give higher or lower reviews than average. We will look at the prediction algorithm with just a user effect, and then add the user effect to the movie effect algorithm above.

```{r}
#Find the mean effect per user
user <- edx %>% group_by(userId) %>% summarize(buser = mean(rating-mu))

#Predict by adding the user effect to the population mean
pred <- validation %>% left_join(user, by="userId") %>% 
  mutate(pred = ifelse(mu + buser > 5, 5, mu + buser)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "User Effect only", RMSE = RMSE(pred)))
```
```{r}
#Predict by adding the user effect to the movie effect algorithm
pred <- validation %>% left_join(movie, by="movieId") %>%
  left_join(user, by="userId") %>% mutate(pred = ifelse(mu + bmov + buser > 5, 5,
                                                        mu + bmov + buser)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Movie Effect + User Effect", RMSE = RMSE(pred)))
```

We see that user only (.978) was worse than movie only, but user effect added to the movie effect gave us another significant improvement to .885.

### Dates
From the exploratory analysis, it did not appear that the year of the movie's release (movie_yr) nor the year of the review (review_yr) will have a considerable effect on RMSE, due to the high variability across the population.  However, the nostalgia index (review_yr - movie_yr) had less variability, so we will see if has any significant effect on the prediction.

```{r}
nidx <- edx %>% group_by(nostalgia_idx) %>% summarize(bnost = mean(rating-mu))

pred <- validation %>% 
  left_join(nidx, by = "nostalgia_idx") %>%
  mutate(pred = ifelse(mu + bnost > 5, 5,
                       mu + bnost)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Nostalgia Index Bias", RMSE = RMSE(pred)))
```

The RMSE for just the nostalgia index (1.052) is not significantly better than just using the population mean as a prediction (1.061), so we would not think that adding it to any other algorithm will show any significant improvement. However, to confirm, we will add it to the movie and user effects to see what it does.

```{r}
pred <- validation %>% 
  left_join(movie, by="movieId") %>%
  left_join(user, by="userId") %>%
  left_join(nidx, by = "nostalgia_idx") %>%
  mutate(pred = ifelse(mu + bmov + buser + bnost > 5, 5,
                       mu + bmov + buser + bnost)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Movie + User + Nostalgia", RMSE = RMSE(pred)))
```

The RMSE of 0.896 is worse than just movie plus user, so we will not use nostalgia index (or any other date-related field) in the final model.

### Genre effect
Since there are potentially multiple genres for a single movie, we can model the genre effect in two ways:

* Total of the genre effects
* Mean genre effect

#### Total genre effect
First we will need to put find the effect for each genre, then join that result into the validation set.

```{r}
find_genre_effect <- function(x) {
  tmp <- edx %>% mutate( gr = ifelse (genre1 == x | genre2 == x |
                                        genre3 == x | genre4 == x |
                                        genre5 == x | genre6 == x |
                                        genre7 == x | genre8 == x, x, NA) )
  tmp %>% filter(! is.na(gr)) %>% group_by(gr) %>% summarize(bgen = mean(rating-mu)) %>% .$bgen
}

gre <- sapply(all_genres, find_genre_effect)
gred <- data.frame(genre=names(gre), bgen = gre, stringsAsFactors = FALSE)
```

Since there are up to 8 genres per movie, we have to join the effects table 8 times. Each singular join looks like the following (the remaning 7 are done in the background):
```{r}
validation <- validation %>%
  left_join(gred, by=c("genre1" = "genre")) %>%
  mutate(bgen1 = bgen) %>% 
  select(-bgen)
```
```{r, echo=FALSE}
validation <- validation %>%
  left_join(gred, by=c("genre2" = "genre")) %>%
  mutate(bgen2 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre3" = "genre")) %>%
  mutate(bgen3 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre4" = "genre")) %>%
  mutate(bgen4 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre5" = "genre")) %>%
  mutate(bgen5 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre6" = "genre")) %>%
  mutate(bgen6 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre7" = "genre")) %>%
  mutate(bgen7 = bgen) %>% 
  select(-bgen)

validation <- validation %>%
  left_join(gred, by=c("genre8" = "genre")) %>%
  mutate(bgen8 = bgen) %>% 
  select(-bgen)
```

We can now total all of the genre effects and add it to the movie and user effects to get a prediction.

```{r}
validation <- validation %>% 
  mutate(total_bgen = ifelse(is.na(bgen1),0,bgen1)+
           ifelse(is.na(bgen2),0,bgen2)+
           ifelse(is.na(bgen3),0,bgen3)+
           ifelse(is.na(bgen4),0,bgen4)+
           ifelse(is.na(bgen5),0,bgen5)+
           ifelse(is.na(bgen6),0,bgen6)+
           ifelse(is.na(bgen7),0,bgen7)+
           ifelse(is.na(bgen8),0,bgen8))

pred <- validation %>%
  left_join(movie, by="movieId") %>%
  left_join(user, by="userId") %>%
  mutate(pred = ifelse(mu + bmov + buser+total_bgen > 5, 5,
                       mu + bmov + buser+total_bgen)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Movie + User + Total Genre", RMSE = RMSE(pred)))
```

The RMSE adding in the total genre effect is worse than that of the movie and user alone, so we will not use that in the final model.

#### Mean genre effect
For the mean genre effect, instead of totalling the effects of the genres of a movie, we take the average of the effects of all the genres on a movie. We use an "unpivot" method to calculate the mean genre effect.

```{r}
mean_genre <- validation %>% select(movieId,
                                    bgen1, bgen2, bgen3, bgen4,
                                    bgen5, bgen6, bgen7, bgen8) %>%
  gather(key=effect, value=genre_effect, -movieId)

mean_genre <- mean_genre %>%
  group_by(movieId) %>% summarize(mean_bgen = mean(genre_effect, na.rm=TRUE))

pred <- validation %>%
  left_join(movie, by="movieId") %>%
  left_join(user, by="userId") %>%
  left_join(mean_genre, by="movieId") %>%
  mutate(pred = ifelse(mu + bmov + buser + mean_bgen > 5, 5,
                       mu + bmov + buser + mean_bgen)) %>% .$pred

RMSE(pred)
```
```{r, echo=FALSE}
results <- rbind(results, data.frame(model = "Movie + User + Mean Genre", RMSE = RMSE(pred)))
```

The results for the mean genre effect (0.892) are better than that of the total genre effect (0.911), but both are still not as good as movie and user alone. Genre by itself will not be used in the final model.

```{r}
results %>% arrange(desc(RMSE)) %>% grid.table()
```

